{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e9ecc-956e-4397-96c6-c1d9b6d29e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This code trains an agent (which is a DNN) to mix a set of active particles \n",
    "to mix a binary system of passive particles. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c326de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from math import pi, ceil, sqrt\n",
    "import time\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import ctypes\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f157e92e",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91019a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "INT_RAD = 1.0 # Radius of interior particle\n",
    "DOMAIN_TO_RAD = 15 # Ratio of domain radius to interior particle radius\n",
    "INT_DIA = 2.0*INT_RAD  # Diameter of interior particle\n",
    "DOMAIN_RAD = DOMAIN_TO_RAD * INT_RAD  #  Radius of the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4efee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_rad = INT_RAD # Radius of a particle\n",
    "cell_width = 4*part_rad # single cell width for force calculation\n",
    "nn_cell_width = 4*part_rad # single cell width for mixing index calculation\n",
    "sq_cutoff_rad = (nn_cell_width)**2 # for the search radius r_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ec6104",
   "metadata": {},
   "source": [
    "Declare C function prototypes for \"mixing.c\": \n",
    "To communicate with Particle Dynamic Subroutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shared library to communicate with Particle Dynamic Sub-routine\n",
    "path = os.getcwd()\n",
    "mixing_lib = ctypes.CDLL(os.path.join(path,'mixing.so')) # '.so' is the compiled C file name\n",
    "\n",
    "# Define the C function signature\n",
    "process = mixing_lib.mix_state\n",
    "process.argtypes = [ctypes.POINTER(ctypes.c_double), ctypes.POINTER(ctypes.c_double),\\\n",
    "                    ctypes.c_int, ctypes.c_int, ctypes.c_double, ctypes.c_double,\\\n",
    "                    ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.c_double]#, ctypes.c_double, ctypes.c_double]\n",
    "#state, thetaRL, rows, cols, P_rad, D_rad, N_wall, N_passive, N_active, delta_t, Time\n",
    "process.restype = ctypes.POINTER(ctypes.c_double)\n",
    "\n",
    "# To free the dynamic array in C code\n",
    "dealloc_mem = mixing_lib.free_array\n",
    "dealloc_mem.argtypes = [ctypes.POINTER(ctypes.c_double)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b28824",
   "metadata": {},
   "source": [
    "Function call for mixing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling Particle Dynamic Sub-routine\n",
    "def call_mix_function(state_array, theta_array, del_t):\n",
    "    rows = state_array.shape[0] # No of rows \n",
    "    cols = state_array.shape[1]\n",
    "    \n",
    "    # Convert the state to a flat C-style array\n",
    "    state_array = state_array.astype(np.float64)\n",
    "    state_array_flat = state_array.flatten(order='C')\n",
    "    cstyle_state = state_array_flat.ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n",
    "    \n",
    "    # Convert theta to a C-style array\n",
    "    theta_array = theta_array.astype(np.float64)\n",
    "    cstyle_theta = theta_array.ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n",
    "\n",
    "    #Passing arguements to C function.................................................\n",
    "    new_state = process(cstyle_state, cstyle_theta, rows, cols, INT_RAD, DOMAIN_RAD,\\\n",
    "                        N_WALL, N_PASSIVE, N_ACTIVE, del_t)#,Time)\n",
    "    #...................................................................................\n",
    "    \n",
    "    # Convert the pointer to a Python array\n",
    "    python_state = np.ctypeslib.as_array(new_state, shape=(rows * cols,))\n",
    "    \n",
    "    # convert from 1D to 2D Python array\n",
    "    mod_state = python_state.reshape(rows,cols).copy()\n",
    "    \n",
    "    # Free the allocated memory in C\n",
    "    dealloc_mem(new_state)\n",
    "    \n",
    "    return mod_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5af21",
   "metadata": {},
   "source": [
    "Mixing Index Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532bed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the Mixing Index\n",
    "def nn_fn(data_passive):\n",
    "    '''Data passive holds the x,y poitions for passive particles'''\n",
    "    nn_list = np.zeros(N_PASSIVE,dtype=int)\n",
    "    posx_nn = data_passive[:,0]\n",
    "    posy_nn = data_passive[:,1]\n",
    "    head_nn = np.ones(N_cells_nn)*(-1)\n",
    "    cell_x_nn = (np.divide(np.subtract(posx_nn,x_low_nn),nn_cell_width)).astype(int) # Putting agent into respective xcell\n",
    "    cell_y_nn = (np.divide(np.subtract(posy_nn,y_low_nn),nn_cell_width)).astype(int); # Putting agent into respective ycell\n",
    "    cell_pos_nn = (cell_x_nn*Nc_y_nn + cell_y_nn).astype(int); # Cell number calculated vertically\n",
    "    \n",
    "    #assigning particles' (identity) in head2 & nn_list for easily accessing\n",
    "    for i in range (N_PASSIVE):\n",
    "        nn_list[i] = head_nn[cell_pos_nn[i]]\n",
    "        head_nn[cell_pos_nn[i]] = i\n",
    "\n",
    "    # To save the number of type\n",
    "    pass_type = np.zeros((N_PASSIVE,2)) \n",
    "\n",
    "    for i in range (Nc_x_nn):\n",
    "        for j in range (Nc_y_nn):\n",
    "            nn_cell_n = i*Nc_y_nn + j\n",
    "            iat = int(head_nn[nn_cell_n])\n",
    "            while (iat != -1): # -1 implies no particles in this head/cell \n",
    "                for neigh_cell_x in [i-1,i,i+1]:\n",
    "                    for neigh_cell_y in [j-1,j,j+1]:\n",
    "                        neigh_cell_n = neigh_cell_x*Nc_y_nn + neigh_cell_y\n",
    "                        jat = int(head_nn[neigh_cell_n])\n",
    "                        while (jat != -1): # -1 implies no particles in this head/cell \n",
    "                            if(iat != jat):\n",
    "                                # Distance calculation of neighboring particles\n",
    "                                dx = posx_nn[jat] - posx_nn[iat]\n",
    "                                dy = posy_nn[jat] - posy_nn[iat]\n",
    "                                sq_distance = dx*dx + dy*dy\n",
    "                                \n",
    "                                if (sq_distance <=sq_cutoff_rad):\n",
    "                                    if(jat<PASSIVE_HALF):\n",
    "                                        pass_type[iat][0] += 1 # TYPE 1 PASSIVE\n",
    "                                    if(jat>=PASSIVE_HALF):\n",
    "                                        pass_type[iat][1] += 1 # TYPE 2 PASSIVE\n",
    "\n",
    "                            jat = int(nn_list[jat])\n",
    "\n",
    "                iat = nn_list[iat]\n",
    "                \n",
    "    ratio_1 = np.sum(2*np.nan_to_num(np.divide(pass_type[:PASSIVE_HALF,1],(pass_type[:PASSIVE_HALF,0]+pass_type[:PASSIVE_HALF,1]))),axis=0)\n",
    "    ratio_2 = np.sum(2*np.nan_to_num(np.divide(pass_type[-PASSIVE_HALF:,0],(pass_type[-PASSIVE_HALF:,0]+pass_type[-PASSIVE_HALF:,1]))),axis=0)\n",
    "    mix_index = (ratio_1+ratio_2)/N_PASSIVE #Mixing Index\n",
    "\n",
    "    return mix_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d0fc8",
   "metadata": {},
   "source": [
    "Functions in class Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulate:\n",
    "\n",
    "    \"\"\"To read initial particle positions and assign values to the arrays and variables used\"\"\"\n",
    "    @staticmethod\n",
    "    def interiorParticlesRead():\n",
    "        global theta, rad, vel, part_type,  N_WALL, N_PASSIVE, N_ACTIVE,\\\n",
    "            INT_PARTICLES, N_TOTAL, PASSIVE_HALF, x_low_nn, y_low_nn, x_max_nn,\\\n",
    "            y_max_nn, Nc_x_nn, Nc_y_nn, N_cells_nn\n",
    "        part = pd.read_csv(\"ini_state_q1.csv\", header = 0, delimiter=\"\\t\", names=[\"x\", \"y\",\\\n",
    "                        \"radius\", \"part_type\"])#Read values and assigned under these headers\n",
    "        pos_x = np.asarray(part['x']) #Assigns the values under x to an array named pos_x\n",
    "        pos_y = np.asarray(part['y']) #Assigns the values under y to an array named pos_y\n",
    "        rad = np.asarray(part['radius']).reshape(-1,1) # radius of all particles used\n",
    "        \n",
    "        '''Type of particle : 1:active,-1:passive, 0:boundary'''\n",
    "        part_type = np.asarray(part['part_type']).reshape(-1,1)\n",
    "\n",
    "        '''values needed to define neighbouring cells to search for neighbours \n",
    "           - helps to search for neighbours faster. used in mixing index calculation'''        \n",
    "        x_low_nn = np.amin(pos_x)-nn_cell_width\n",
    "        y_low_nn = np.amin(pos_y)-nn_cell_width\n",
    "        x_max_nn = np.amax(pos_x)+nn_cell_width\n",
    "        y_max_nn = np.amax(pos_y)+nn_cell_width\n",
    "        Nc_x_nn = int(np.ceil((x_max_nn-x_low_nn)/nn_cell_width))\n",
    "        Nc_y_nn = int(np.ceil((y_max_nn-y_low_nn)/nn_cell_width))\n",
    "        N_cells_nn = int(Nc_x_nn*Nc_y_nn) # Total no of cells\n",
    "        \n",
    "        N_WALL = len((part_type[part_type==0]))\n",
    "        N_PASSIVE = len((part_type[part_type==-1]))\n",
    "        N_ACTIVE = len((part_type[part_type==1]))\n",
    "        INT_PARTICLES = N_ACTIVE + N_PASSIVE\n",
    "        N_TOTAL = INT_PARTICLES + N_WALL\n",
    "        PASSIVE_HALF = int(N_PASSIVE/2)\n",
    "        del part # Memory freed\n",
    "    \n",
    "    '''Initial state : (x, y) of passive & active particles'''\n",
    "    def readInitialState():\n",
    "        \"\"\"\n",
    "        Ensure all data is entered through a single file in the format given below.\n",
    "        Ensure the data is in order of wall data, passive data and active data \n",
    "        from top to bottom.The initial input file contained u,v velocities from which \n",
    "        orientation (theta) is calculated.\n",
    "        \"\"\"\n",
    "        #active, passive, and wall data : x, y, rad, vel, theta, type : indices :0 1 2 3 4 5\n",
    "        global wall_state\n",
    "        part = pd.read_csv(\"ini_state_q1.csv\", delimiter=\"\\t\",header=0) \n",
    "        initial_state = part.to_numpy(dtype=float)\n",
    "        int_state = initial_state[:INT_PARTICLES, :2] # Storing initial position of active particles of active particles\n",
    "        wall_state = initial_state[INT_PARTICLES:, :2] # Storing wall particle x,y data\n",
    "        del part\n",
    "        return int_state # Returns initial state : (x, y) of passive & active particles   \n",
    "    \n",
    "    '''Receives a state, does dynamics through a series of sub functions and returns new state'''\n",
    "    @staticmethod\n",
    "    def systemState(interior_state, theta_RL, delta_t): # receives (x, y), theta(RL) data - for active+passive separate\n",
    "        global wall_state, rad, part_type\n",
    "        state = np.concatenate((interior_state,wall_state), axis=0) # active+passive+wall - x,y data\n",
    "        theta_up = np.concatenate((theta_RL, np.zeros(N_PASSIVE) , np.zeros(N_WALL)),axis=0).reshape(-1,1)\n",
    "        c_state = np.hstack((state, rad, part_type)) # x,y,rad,part_type for all particles\n",
    "\n",
    "        #......................................................\n",
    "        up_state = call_mix_function(c_state,theta_up,delta_t) # CALLING FUNCTION FOR MIXING\n",
    "        '''up_state is the updated state of the system after delta_t time'''\n",
    "        #......................................................\n",
    "         \n",
    "        '''rew is the reward or mixing index(MI) based on current position of passive particles'''\n",
    "        rew = nn_fn(up_state[N_ACTIVE:INT_PARTICLES,:2]) #passing passive positions to find MI\n",
    "    \n",
    "        obs_state = up_state[:INT_PARTICLES, :2] # x,y positions of both active + passsive\n",
    "        return obs_state, rew # Returning passive, active states separately along \n",
    "                            # with reward(MI) after delta_t time - delta_t/dt iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d3703",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To initiate the variables and arrays used'''\n",
    "Simulate.interiorParticlesRead()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8432a80",
   "metadata": {},
   "source": [
    "# RL Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ec9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tqdm\n",
    "import rich\n",
    "from gym import spaces\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a788506b",
   "metadata": {},
   "source": [
    "Directories for Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631153c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"models/PPO\"\n",
    "log_dir =  \"logs\"\n",
    "\n",
    "if not os.path.exists(models_dir):  # Create directory particle_data for storing data\n",
    "  os.makedirs(models_dir)\n",
    "if not os.path.exists(log_dir):  # Create directory particle_data for storing data\n",
    "  os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae16f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_time = 50000.0 # Total Simulation Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c3d48",
   "metadata": {},
   "source": [
    "Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''t_sim determines the time duration for an episode'''\n",
    "'''delta_t is the interval with in which RL interacts with C subroutine'''\n",
    "\n",
    "\"\"\"ParticleMixer is the Custom Environment that follows gym interface\"\"\"\n",
    "class ParticleMixer(gym.Env):\n",
    "\n",
    "    '''To initiate the variables and arrays in the environment, a constructor is used'''\n",
    "    def __init__(self, n_dim=2, t_sim=sim_time, delta_t=20.0, rr=0):  # self is a constructor\n",
    "        super(ParticleMixer, self).__init__()\n",
    "        self.n_obs = INT_PARTICLES  # Observing particle count\n",
    "        self.n_active = N_ACTIVE # No of active particles\n",
    "        \n",
    "        # Define the pool of angles\n",
    "        self.angle_pool = np.arange(0, 2.0*pi, pi/2) \n",
    "        '''pool of angles is in steps of pi/2 - can be replaced with the angle of our choice'''\n",
    "\n",
    "        # Setting up the action space                                                                                                            \n",
    "        self.action_space = gym.spaces.MultiDiscrete([len(self.angle_pool)] * self.n_active)\n",
    "\n",
    "        '''Defining the observation space that contains x,y for active and passive\n",
    "           Defined as a 1-D array'''\n",
    "        self.observation_space = spaces.Box(low=0, high=2*DOMAIN_RAD,\n",
    "                                            shape=((self.n_obs)*n_dim, ), dtype=np.float64)  # Observation space size: [n_passive+n_active] x 2 : (x,y)                                    \n",
    "\n",
    "        self.obs_state = np.zeros((self.n_obs,2), dtype=np.float64) # 2 columns (x,y)\n",
    "        self.time_statistics = np.zeros((5000,2), dtype=float) # To save episode no and length\n",
    "        self.t_sim = t_sim # Maximum simulation time for 1 episode\n",
    "        self.n_time = 0.0 # Current iteration\n",
    "        self.del_t = delta_t # Duration between agent-environment interaction\n",
    "        self.t = 0.0 # Current time\n",
    "        self.row=rr # To point to the row in time_statistics\n",
    "        self.prev_action = self.action_space.sample() # creates a sample action space\n",
    "        self.done = False # To determine if the episode is over. False:Not Over, True:Over\n",
    "\n",
    "    def step(self, action): #This function is called by alg after reset function to perform the action\n",
    "                            # This function is linked to the system dynamics equation\n",
    "        self.action_val = [self.angle_pool[i] for i in action]  # Sampled angles for active particles\n",
    "        #print(self.prev_action)\n",
    "        \n",
    "        \"\"\" To find & assign velocity when angle \"d_theta\" is the action_space \"\"\"\n",
    "\n",
    "        #self.active_state[:,2] = self.prev_action  # theta assigned\n",
    "\n",
    "        self.obs_state, index = Simulate.systemState(self.obs_state, self.action_val, self.del_t) # sending x, y, theta\n",
    "        \"\"\" Send current [position, theta] and returns new [position, theta] after implementing Langevin code for delta_t time\"\"\"\n",
    "        \n",
    "        '''We take the -ve of index as reward. As mixing is better, index value decreases\n",
    "        If we take the negative, the value can be seen increasing with mixing (in the -ve range towards 0)\n",
    "        As the algorithm tends to maximise reward, the cumulative reward should be closer to 0'''\n",
    "        reward = index \n",
    "        observation = self.obs_state.flatten() # self.observation_space.sample()\n",
    "        info = {}\n",
    "        self.t += self.del_t  # Total Time Completed\n",
    "        self.n_time += self.del_t/0.01  # Total Timesteps completed\n",
    "        if ((self.t > self.t_sim)|(reward>=0.99)): \n",
    "            self.done = True\n",
    "            self.time_statistics[self.row,0] = self.t\n",
    "            self.time_statistics[self.row,1] = reward\n",
    "            self.row = self.row+1\n",
    "        return observation, reward, self.done, info\n",
    "\n",
    "    def reset(self): #While running the RL algorithm, this function is called first. This sets initial observation space\n",
    "        self.t = 0.0\n",
    "        self.n_time = 0.0\n",
    "        self.done=False     \n",
    "        self.obs_state = Simulate.readInitialState() # Resetting the initial state before an episode during first case : (x, y, theta(from i/p file))\n",
    "        observation = self.obs_state.flatten() # 1-D initial state\n",
    "#         print(\"1 reset\")\n",
    "        return observation  # reward, done, info can't be included\n",
    "    def render(self):\n",
    "        pass\n",
    "    def close (self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b681630",
   "metadata": {},
   "source": [
    "Assigning environment to variable env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ParticleMixer() # env is the environment now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f20e3",
   "metadata": {},
   "source": [
    "Check the custom environment for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd293fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85533f44",
   "metadata": {},
   "source": [
    "Algorithm and Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eb8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b9861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom MLP policy with Relu activation function\n",
    "policy_kwargs = dict(activation_fn=th.nn.ReLU, net_arch=[512,256,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hyperparameters = {\n",
    "    'learning_rate': 0.000001,\n",
    "    # Add other hyperparameters and their new values here separeted by commas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bcdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"models/PPO\" # Directory for saving the models\n",
    "log_dir =  \"logs\" # Directory for saving the data for tensor board view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ppo = PPO('MlpPolicy', env, verbose=1, policy_kwargs=policy_kwargs, **new_hyperparameters, tensorboard_log=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955cf9f2",
   "metadata": {},
   "source": [
    "Learning happens here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfad99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Intermediate models are saved after every 4096 agent-env communications'''\n",
    "learn_start = time.time()\n",
    "for i in range(300):# repeat the total_timesteps 300 times\n",
    "    model_ppo.learn(total_timesteps=4096, reset_num_timesteps=False, tb_log_name=\"PPO\")\n",
    "    model_ppo.save(f\"{models_dir}/{i+1}\") # Saving the trained model\n",
    "    if (i+1)%100==0:\n",
    "        outfile = \"maxtime_vs_maxMI_statistics.csv\"\n",
    "        df = pd.DataFrame(env.time_statistics,columns=['max_time','max_MI'])\n",
    "        df.to_csv(outfile, index=False, sep='\\t')\n",
    "print(\"learn_time = \",time.time()-learn_start) # Printing time taken to learn\n",
    "\n",
    "'''\n",
    "the policy is updated after every \"n_steps\" iterations - 2048 default (agent-env communications)\n",
    "the model is saved after every \"total_timesteps\" iterations and \n",
    "continue to iterate until for loop is over -->final time_steps = 300*4096\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7446726",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Save the episode length for each episode along with MI'''\n",
    "outfile = \"maxtime_vs_maxMI_statistics_final.csv\"\n",
    "df = pd.DataFrame(env.time_statistics,columns=['max_time','max_MI'])\n",
    "df.to_csv(outfile, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d8f9a-2bc2-443e-98fb-fc3826c2c1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
